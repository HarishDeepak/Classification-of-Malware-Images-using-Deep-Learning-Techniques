{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN7TQs2Tc/t89lZ00gX1w4O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarishDeepak/Classification-of-Malware-Images-using-Deep-Learning-Techniques/blob/main/A_Novel_Method_for_Classification_of_Malware_Images_using_Deep_Learning_Techniques.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4ETq5JdI9M6L"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "import glob\n",
        "import torch.nn as nn\n",
        "from torchvision.transforms import transforms\n",
        "from torch.optim import Adam\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "import pathlib\n",
        "import zipfile\n",
        "import math\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import shutil\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        " torch.backends.cudnn.deterministic = True\n",
        "from google.colab import drive\n",
        "drive.mount ('/content/gdrive')\n",
        "!unzip \"/content/gdrive/MyDrive/Malware_ISM/Malware1.zip\" -\n",
        "d \"/content/malware-images\"\n",
        "transformer=transforms.Compose([\n",
        " transforms.Resize((256,256)),\n",
        " transforms.ToTensor(), #0-255 to 0-1, numpy to tensors\n",
        "])\n",
        "dataset_path = '/content/malware-images/Malimg_Dataset/'\n",
        "def load_dataset():\n",
        " train_dataset_manual = torchvision.datasets.ImageFolder(dataset_pat\n",
        "h, transform=transformer)\n",
        " train_loader_manual = torch.utils.data.DataLoader(train_dataset_man\n",
        "ual)\n",
        " return train_loader_manual\n",
        "full_dataset = load_dataset()\n",
        "\n",
        "train_size = int(0.6 * len(full_dataset))\n",
        "test_size = int (0.2 * len(full_dataset))\n",
        "valid_size = len(full_dataset) - train_size - test_size\n",
        "train_dataset, test_dataset, valid_dataset = torch.utils.data.random_sp\n",
        "lit(full_dataset.dataset, [train_size, test_size, valid_size])\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, num_wor\n",
        "kers=0, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, num_worke\n",
        "rs=0, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, num_wor\n",
        "kers=0, shuffle=True)\n",
        "print('Full Dataset - ' + str(len(full_dataset)) + ' images.')\n",
        "print('Train Set- ' + str(train_size) + ' images in ' + str(len(train_l\n",
        "oader)) +' batches')\n",
        "print('Testing Set - ' + str(test_size) + ' images in ' + str(len(test_\n",
        "loader)) + ' batches' )\n",
        "print('Validation Set - ' + str(valid_size) + ' images in ' + str(len(v\n",
        "alid_loader)) + ' batches')\n",
        "for images, labels in train_loader:\n",
        " print('Image batch dimensions:', images.shape)\n",
        " print('Image label dimensions:', labels.shape)\n",
        " break\n",
        "root = pathlib.Path (dataset_path)\n",
        "classes = sorted ([j.name.split('/')[-1] for j in root.iterdir()])\n",
        "print (classes)\n",
        "print(len(classes))\n",
        "device = torch.device (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class MyModel(nn.Module):\n",
        " def __init__(self):\n",
        " super(MyModel, self).__init__()\n",
        " self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        " self.bn1 = nn.BatchNorm2d(16)\n",
        " self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        " self.bn2 = nn.BatchNorm2d(32)\n",
        " self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
        " self.bn3 = nn.BatchNorm2d(64)\n",
        " self.conv4 = nn.Conv2d(64, 128, 3, padding=1)\n",
        " self.bn4 = nn.BatchNorm2d(128)\n",
        " self.conv5 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "\n",
        " self.bn5 = nn.BatchNorm2d(256)\n",
        " self.pool = nn.MaxPool2d(2, 2)\n",
        " self.fc1 = nn.Linear(256 * 8 * 8, 1024)\n",
        " self.fc2 = nn.Linear(1024, 512)\n",
        " self.fc3 = nn.Linear(512, 25)\n",
        " self.dropout = nn.Dropout(0.2)\n",
        " def forward(self, x):\n",
        " x = self.bn1(F.relu(self.conv1(x)))\n",
        " x = self.pool(x)\n",
        " x = self.bn2(F.relu(self.conv2(x)))\n",
        " x = self.pool(x)\n",
        " x = self.bn3(F.relu(self.conv3(x)))\n",
        " x = self.pool(x)\n",
        " x = self.bn4(F.relu(self.conv4(x)))\n",
        " x = self.pool(x)\n",
        " x = self.bn5(F.relu(self.conv5(x)))\n",
        " x = self.pool(x)\n",
        " x = x.view(-1, 256 * 8 * 8)\n",
        " x = self.dropout(F.relu(self.fc1(x)))\n",
        " x = self.dropout(F.relu(self.fc2(x)))\n",
        " x = self.fc3(x)\n",
        " return x\n",
        "net = MyModel()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "path='/content/gdrive/MyDrive/Malware_ISM/Malware_25Epochs'\n",
        "net.load_state_dict(torch.load(path))\n",
        "!pip install efficientnet_pytorch\n",
        "import torch\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "PATHa = '/content/gdrive/MyDrive/content/EfficientNet/Malware_25Epochs'\n",
        "PATHb = '/content/gdrive/MyDrive/Malware_ISM/Malware_15Epochs'\n",
        "#Load Models\n",
        "modelA = MyModel()\n",
        "modelB = EfficientNet.from_pretrained('efficientnet-b0').to(device)\n",
        "import torch.nn as nn\n",
        "# define new instance of the model\n",
        "modelA = MyModel()\n",
        "# load state_dict into the new model instance\n",
        "modelA.load_state_dict(torch.load(PATHb))\n",
        "class Ensemble(nn.Module):\n",
        " def __init__(self, model1, model2):\n",
        "\n",
        " super(Ensemble, self).__init__()\n",
        " self.model1 = model1\n",
        " self.model2 = model2\n",
        "\n",
        " def forward(self, x):\n",
        " out1 = self.model1(x)\n",
        " out2 = self.model2(x)\n",
        " out = (out1 + out2) / 2\n",
        " return out\n",
        "model1 = modelA\n",
        "model2 = modelB\n",
        "model2._fc = nn.Linear(in_features=model2._fc.in_features, out_features\n",
        "=25, bias=True)\n",
        "ensemble_model = Ensemble(model1, model2)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "SRECEe_Y_I0L",
        "outputId": "f439f75b-84a6-4e83-8b45-2e3adc3d6e9c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-c6db75eb4663>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    d \"/content/malware-images\"\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(ensemble_model.parameters(), lr=0.001)\n",
        "# Move the model to the GPU\n",
        "ensemble_model = ensemble_model.to(device)\n",
        "import tensorflow as tf\n",
        "checkpoint_path = \"/content/gdrive/MyDrive/Malware_ISM/Malware_Combined_5Epochs\"\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "   checkpoint_path, verbose=1, save_weights_only=True,\n",
        " # Save weights, every epoch.\n",
        " save_freq='epoch')\n",
        "num_epochs = 15\n",
        "\n"
      ],
      "metadata": {
        "id": "hilwqwjt_IHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        " for epoch in range(num_epochs):\n",
        "# validation\n",
        " ensemble_model.eval()\n",
        " val_running_loss = 0.0\n",
        " val_correct = 0\n",
        " val_total = 0\n",
        " with torch.no_grad():\n",
        " for inputs, labels in valid_loader:\n",
        " inputs = inputs.to(device)\n",
        " labels = labels.to(device)\n",
        " outputs = ensemble_model(inputs)\n",
        " loss = criterion(outputs, labels)\n",
        "\n",
        " val_running_loss += loss.item()\n",
        " _, predicted = torch.max(outputs.data, 1)\n",
        " val_total += labels.size(0)\n",
        " val_correct += (predicted == labels).sum().item()\n",
        "\n",
        " val_loss = val_running_loss / len(valid_loader)\n",
        " val_accuracy = 100 * val_correct / val_total\n"
      ],
      "metadata": {
        "id": "BKKAa30t-hhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        " # print results\n",
        " print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f}| Train Acc: {train_accuracy:.2f}% | Val Loss: {val_loss:.4f} | Val Acc: {val_accuracy:.2f}%\")\n",
        "torch.save(net.state_dict(),'/content/gdrive/MyDrive/Malware_ISM/Malware_Combined_20Epochs')\n",
        "path='/content/gdrive/MyDrive/Malware_ISM/Malware_Combined_20Epochs'\n",
        "net.load_state_dict(torch.load(path))\n",
        "print(ensemble_model.keys())\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "y_pred = []\n",
        "y_true = []"
      ],
      "metadata": {
        "id": "ZRNHj3C--cFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# iterate over test data\n",
        "\n",
        "#for inputs, labels in test_loader:\n",
        "for i, (images, labels) in enumerate(test_loader):\n",
        " images, labels = images.to(device), labels.to(device)\n",
        " net = net.to(device)\n",
        " output = net(images) # Feed Network\n",
        " output = (torch.max(torch.exp(output), 1)[1])\n",
        " output = output.data.cpu().numpy()\n",
        " y_pred.extend(output) # Save Prediction\n",
        "\n",
        " labels1 = labels.data.cpu().numpy()\n",
        " y_true.extend(labels1) # Save Trut\n",
        "print (len(y_pred))\n",
        "print (len(y_true))\n",
        "print(y_pred)\n",
        "print(y_true)\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "cf_matrix = confusion_matrix(y_true, y_pred)\n",
        "df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix) *10, index = [i for i\n",
        "in classes],\n",
        " columns = [i for i in classes])\n",
        "plt.figure(figsize = (25,25))\n",
        "sn.heatmap(df_cm, annot=True)\n",
        "classification_report(y_true, y_pred,zero_division=0,output_dict=True)"
      ],
      "metadata": {
        "id": "HJxVnKzh-Lvm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}